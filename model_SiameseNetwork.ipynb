{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import tqdm\n",
    "import os\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "from torchvision.models.alexnet import AlexNet\n",
    "from torchvision.models.resnet import resnet18, resnet34, resnet50, resnet101, resnet152\n",
    "from torch.utils.data import IterableDataset, DataLoader, Dataset\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, average_precision_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "def linear_combination(x, y, epsilon): \n",
    "    return epsilon*x + (1-epsilon)*y\n",
    "\n",
    "\n",
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
    "\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, epsilon:float=0.1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, preds, target):\n",
    "        n = preds.size()[-1]\n",
    "        log_preds = F.log_softmax(preds, dim=-1)\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        return linear_combination(loss/n, nll, self.epsilon)\n",
    "    \n",
    "    \n",
    "class BonzTrainDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super(BonzTrainDataset, self).__init__()\n",
    "        self.image_prefixes = data.image_prefixes.values\n",
    "        self.features = data.features.values\n",
    "        self.img_tensors = data.img_tensors.values\n",
    "        if 'labels' in data:\n",
    "            self.labels = data.labels.values\n",
    "            self.one_hot_labels = data.one_hot_labels.values\n",
    "        else:\n",
    "            self.labels=None\n",
    "    \n",
    "    def __len__(self):\n",
    "        #return 3000\n",
    "        return len(self.image_prefixes)**2\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ''' Full data'''\n",
    "        x1 = idx // len(self.image_prefixes)\n",
    "        x2 = idx % len(self.image_prefixes)\n",
    "        \n",
    "        \n",
    "        ''' Random select\n",
    "        x1 = random.randint(0, len(self.image_prefixes)-1)\n",
    "        x2 = random.randint(0, len(self.image_prefixes)-1)\n",
    "        \n",
    "        if idx%3 == 0:\n",
    "            while self.labels[x1] != self.labels[x2]:\n",
    "                x2 = random.randint(0, len(self.image_prefixes)-1)\n",
    "        else:\n",
    "            while self.labels[x1] == self.labels[x2]:\n",
    "                x2 = random.randint(0, len(self.image_prefixes)-1)\n",
    "        '''\n",
    "        \n",
    "        outputs = (self.img_tensors[x1], \n",
    "                   self.features[x1], \n",
    "                   self.img_tensors[x2], \n",
    "                   self.features[x2],)\n",
    "        if self.labels[x1] == self.labels[x2]:\n",
    "            outputs += (torch.tensor([1]),)\n",
    "        else:\n",
    "            outputs += (torch.tensor([0]),)\n",
    "        return outputs\n",
    "    \n",
    "        \n",
    "class Bonz(nn.Module):\n",
    "    def __init__(self, hidden_dim=100, feature_selection=12):\n",
    "        super(Bonz, self).__init__()\n",
    "        self.resnet = resnet50(True)\n",
    "        self.BiLSTM = nn.LSTM(2048, hidden_dim, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        self.bn = nn.BatchNorm1d(hidden_dim*2 + feature_selection)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim*2 + feature_selection, hidden_dim*2 + feature_selection),\n",
    "            nn.LeakyReLU(0.001, inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_dim*2 + feature_selection, 1)\n",
    "        )\n",
    "        self.classifier.apply(self._init_weights)\n",
    "        self.classifier.apply(self._xavier)\n",
    "        self.BiLSTM.apply(self._xavier)\n",
    "    \n",
    "    def forward(self, x1, x1_f, x2, x2_f):\n",
    "        ''' PROCESS X1'''\n",
    "        # Generate featuress from each images\n",
    "        x = []\n",
    "        for img in x1:\n",
    "            temp = self.do_resnet(img)\n",
    "            x.append(temp.unsqueeze(0))\n",
    "        x = torch.cat(x, 0)\n",
    "        \n",
    "        # LSTM step\n",
    "        x, _ = self.BiLSTM(x)\n",
    "        lstm_features = x[:,-1,:]\n",
    "        \n",
    "        # Concate features\n",
    "        x1 = torch.cat([lstm_features, x1_f], -1)\n",
    "        #x1 = self.bn(x1)\n",
    "        \n",
    "        ''' PROCESS X2'''\n",
    "        # Generate featuress from each images\n",
    "        x = []\n",
    "        for img in x2:\n",
    "            temp = self.do_resnet(img)\n",
    "            x.append(temp.unsqueeze(0))\n",
    "        x = torch.cat(x, 0)\n",
    "        \n",
    "        # LSTM step\n",
    "        x, _ = self.BiLSTM(x)\n",
    "        lstm_features = x[:,-1,:]\n",
    "        \n",
    "        # Concate features\n",
    "        x2 = torch.cat([lstm_features, x2_f], -1)\n",
    "        #x2 = self.bn(x2)\n",
    "        \n",
    "        ''' DIFFERENCE BETWEEN X1 and X2'''\n",
    "        dif = torch.abs(x1-x2)   \n",
    "        \n",
    "        predict = self.classifier(dif)\n",
    "\n",
    "        return (predict, dif,)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding, nn.Conv1d)):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            if isinstance(module, (nn.Linear, nn.Conv1d)) and module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "            \n",
    "    def _xavier(self, module):\n",
    "        for name, param in module.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.xavier_normal_(param)\n",
    "            elif 'bias' in name:\n",
    "                param.data.zero_()\n",
    "    \n",
    "    def do_resnet(self, img):\n",
    "        x = self.resnet.conv1(img)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "\n",
    "        x = self.resnet.layer1(x)\n",
    "        x = self.resnet.layer2(x)\n",
    "        x = self.resnet.layer3(x)\n",
    "        x = self.resnet.layer4(x)\n",
    "\n",
    "        x = self.resnet.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def freeze_resnet(self):\n",
    "        for w in self.resnet.parameters():\n",
    "            w.requires_grad = False\n",
    "            \n",
    "    def unfreeze_resnet(self):\n",
    "        for w in self.resnet.parameters():\n",
    "            w.requires_grad = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10142d2b9c4f43cea36eefa99ff175be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=280.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8057086e462848879f84c2178911683d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=140.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    resnet_idx = list(data.columns).index('data_AUTOGRAPHER_RESNET_mean_tench, Tinca tinca')\n",
    "    new_data = data.iloc[:,:resnet_idx]\n",
    "    new_data = new_data.drop([col_len for col_len in new_data.keys() if '_len' in col_len], 1) # Drop columns with _LEN\n",
    "    new_data['labels'] = [int(i[-2:])-1 for i in new_data.event_id.values]\n",
    "    new_data['image_prefixes'] = list(map(lambda x,y,z: str(x)+'_'+str(y)+'_'+str(z), \n",
    "                                      new_data.sub_id.values, \n",
    "                                      new_data.source.values, \n",
    "                                      new_data.event_id.values))\n",
    "    new_data['one_hot_labels'] = list(map(lambda x: nn.functional.one_hot(torch.tensor(x), 20).float(), new_data.labels.values))\n",
    "    new_data['features'] = [torch.tensor(i).float() for i in new_data.iloc[:, 3:-3].values]\n",
    "    new_data['img_tensors'] = get_img_tensors(new_data['image_prefixes'].values)\n",
    "    return new_data.iloc[:, -5:]\n",
    "\n",
    "\n",
    "def get_test_data(path):\n",
    "    data = pd.read_csv(path, index_col=0)\n",
    "    resnet_idx = list(data.columns).index('data_AUTOGRAPHER_RESNET_mean_tench, Tinca tinca')\n",
    "    new_data = data.iloc[:,:resnet_idx]\n",
    "    new_data = new_data.drop([col_len for col_len in new_data.keys() if '_len' in col_len], 1) # Drop columns with _LEN\n",
    "    new_data['image_prefixes'] = list(map(lambda x,y: str(x)+'_pred'+str(y), \n",
    "                                      new_data.sub_id.values, \n",
    "                                      new_data.event_id.values))\n",
    "    new_data['features'] = [torch.tensor(i).float() for i in new_data.iloc[:, 3:-1].values]\n",
    "    new_data['img_tensors'] = get_img_tensors(new_data['image_prefixes'].values)\n",
    "    return new_data.iloc[:, [0,1,2,-3,-2,-1]]\n",
    "\n",
    "\n",
    "def get_img_tensors(image_prefixes):\n",
    "    transform = T.Compose([\n",
    "        T.Resize(256),\n",
    "        T.CenterCrop(224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    temp = []\n",
    "    \n",
    "    for img_prefix in tqdm.notebook.tqdm(image_prefixes):\n",
    "        img_paths = []\n",
    "        i = 0\n",
    "        img_name = img_prefix+'_'+str(i)+'.jpg'\n",
    "        while img_name in os.listdir('./OUTPUT_MERGED/AUTOGRAPHER/'):\n",
    "            img_paths.append('./OUTPUT_MERGED/AUTOGRAPHER/'+img_name)\n",
    "            i += 1\n",
    "            img_name = img_prefix+'_'+str(i)+'.jpg'\n",
    "\n",
    "        # Transform images to tensors\n",
    "        img_tensors = []\n",
    "        for path in img_paths:\n",
    "            img = Image.open(path)\n",
    "            img_tensors.append(transform(img))\n",
    "            \n",
    "        # padding img tensors\n",
    "        if len(img_tensors) < 16:\n",
    "            dump = torch.zeros((3,224,224)).float()\n",
    "            dump = [dump] * (16 - len(img_tensors))\n",
    "            img_tensors.extend(dump)\n",
    "            \n",
    "        temp.append(torch.stack(img_tensors,0))\n",
    "    \n",
    "    return temp\n",
    "\n",
    "def check_params(model):\n",
    "    model.freeze_resnet()\n",
    "    print(sum([i.numel() for i in model.parameters() if i.requires_grad]))\n",
    "    model.unfreeze_resnet()\n",
    "    print(sum([i.numel() for i in model.parameters() if i.requires_grad]))\n",
    "    \n",
    "\n",
    "        \n",
    "train_data = get_data('train_min_max.csv')\n",
    "train_data = train_data.sort_values(by='image_prefixes', ignore_index=True)\n",
    "test_data = get_test_data('test_min_max.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185377037\n",
      "210934069\n"
     ]
    }
   ],
   "source": [
    "model = Bonz(hidden_dim=2048, feature_selection=train_data.features[0].shape[0])\n",
    "check_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78400"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = BonzTrainDataset(train_data)\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "dataset.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Best Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tmuds\\miniconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:118: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4299bb7b8d40058114d9da6e0791be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aaea6c7e98945e69a7016af163f321b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training: ', max=47.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=0, Acc=93.83, Loss=0.17, LR=2.00e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e8b1b7b3a841d8b7f0f004f98fe350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training: ', max=47.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=1, Acc=93.73, Loss=0.09, LR=4.00e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8f951327f343a99d24f0bbda0a4c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training: ', max=47.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=2, Acc=93.90, Loss=0.12, LR=6.00e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d7c6c364180488baae93caf4cb168ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training: ', max=47.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=3, Acc=93.70, Loss=0.17, LR=8.00e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a619a65430421392e045c9894f1279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training: ', max=47.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=4, Acc=94.00, Loss=0.04, LR=1.00e-03\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19afe83bd0e342d29173beec17f9b73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4ba5716a3d486b80d0dd2111431107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training: ', max=47.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=0, Acc=94.00, Loss=0.25, LR=2.00e-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32db723d0c3a4423865bbed98f1e7015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training: ', max=47.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=1, Acc=93.93, Loss=0.09, LR=4.00e-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c98d2aeb634647b4010b72be07a3d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training: ', max=47.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=2, Acc=93.80, Loss=0.13, LR=6.00e-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adeaa6d98375402b81dfb32bc1040f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training: ', max=47.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=3, Acc=94.03, Loss=0.21, LR=8.00e-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f50ea072d644df4943012164725dd03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training: ', max=47.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=4, Acc=94.07, Loss=0.09, LR=1.00e-02\n",
      "\n",
      "0.00020000000000000017\t0.9383333333333334\t9.58180908113718\n",
      "0.0003999999999999999\t0.9373333333333334\t9.230482377111912\n",
      "0.0006000000000000001\t0.939\t8.963266298174858\n",
      "0.0007999999999999998\t0.937\t8.816364150494337\n",
      "0.001\t0.94\t8.94610458984971\n",
      "0.0020000000000000018\t0.94\t8.18113087117672\n",
      "0.003999999999999999\t0.9393333333333334\t9.424686886370182\n",
      "0.006000000000000001\t0.938\t8.614524226635695\n",
      "0.007999999999999998\t0.9403333333333334\t8.83814811706543\n",
      "0.01\t0.9406666666666667\t9.135346800088882\n"
     ]
    }
   ],
   "source": [
    "model.freeze_resnet()\n",
    "\n",
    "model.to(DEVICE)\n",
    "torch.save(model.state_dict(), 'origin_sd.pt')\n",
    "model.train()\n",
    "\n",
    "start_lr = 1e-4\n",
    "lr_find_epochs = 5\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), start_lr)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "\n",
    "# Make lists to capture the logs\n",
    "lr_find_acc = []\n",
    "lr_find_loss = []\n",
    "lr_find_lr = []\n",
    "\n",
    "\n",
    "for _ in range(2):\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, \n",
    "                                                  base_lr=0, \n",
    "                                                  max_lr=start_lr*10, \n",
    "                                                  step_size_up=lr_find_epochs,\n",
    "                                                  cycle_momentum=False)\n",
    "    scheduler.step()\n",
    "    \n",
    "    for i in tqdm.notebook.trange(lr_find_epochs):\n",
    "        # Load origin state dict\n",
    "        model.load_state_dict(torch.load('origin_sd.pt'))\n",
    "\n",
    "        predicts = []\n",
    "        y_true = []\n",
    "        total_loss = 0\n",
    "\n",
    "        for x1, x1_f, x2, x2_f, label in tqdm.notebook.tqdm(dataloader, desc='Training: '):\n",
    "\n",
    "            x1 = [ts.to(DEVICE) for ts in x1]\n",
    "            x1_f = x1_f.to(DEVICE)\n",
    "            x2 = [ts.to(DEVICE) for ts in x2]\n",
    "            x2_f = x2_f.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            predict = model(x1, x1_f, x2, x2_f)[0]\n",
    "            loss = criterion(predict, label.float())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            predict = predict.detach().cpu()\n",
    "            predict = torch.sigmoid(predict)\n",
    "            predicts.extend(predict.tolist())\n",
    "            y_true.extend(label.detach().cpu().tolist())\n",
    "\n",
    "        train_acc = accuracy_score(np.array(y_true), np.array(predicts)>0.5)\n",
    "        lr_step = optimizer.state_dict()[\"param_groups\"][0][\"lr\"]\n",
    "        print(f'epoch={i}, Acc={train_acc*100:.2f}, Loss={loss:.2f}, LR={lr_step:.2e}')\n",
    "\n",
    "        lr_find_lr.append(lr_step)\n",
    "        lr_find_acc.append(train_acc)\n",
    "        lr_find_loss.append(total_loss)\n",
    "\n",
    "        scheduler.step()\n",
    "    \n",
    "    start_lr *= 10\n",
    "        \n",
    "        \n",
    "for a, b, c in zip(lr_find_lr, lr_find_acc, lr_find_loss):\n",
    "    print(f'{a}\\t{b}\\t{c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc42be3173a74b6fb05309b367fd2325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c91814a5264ab5a75abe6dd71faba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1225.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=0, Acc=95.52, Loss=0.10\n",
      "BEST MODEL at Epoch = 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a817c5da8ea4362b6802834615ff611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1225.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=1, Acc=96.49, Loss=0.09\n",
      "BEST MODEL at Epoch = 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a119b16f899f445baf5b2ad225c3e3b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1225.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=2, Acc=97.83, Loss=0.09\n",
      "BEST MODEL at Epoch = 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a1dd3b931a4d1eabf60113e1fe0e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1225.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=3, Acc=98.78, Loss=0.01\n",
      "BEST MODEL at Epoch = 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329d366be5d348e9bb8a3a24509cd97d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1225.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=4, Acc=99.02, Loss=0.03\n",
      "BEST MODEL at Epoch = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31907bea71c4439ea6017dcb919baa47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1225.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=5, Acc=99.11, Loss=0.02\n",
      "BEST MODEL at Epoch = 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a127baa1bfd4e10b52cfb4c63c4af5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1225.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=6, Acc=99.35, Loss=0.00\n",
      "BEST MODEL at Epoch = 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1973b6b5b64061b6e307cd760da156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1225.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=7, Acc=99.38, Loss=0.00\n",
      "BEST MODEL at Epoch = 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d9007419fe4bafb753466480bc3a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1225.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=8, Acc=99.58, Loss=0.01\n",
      "BEST MODEL at Epoch = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8efc9d526879468f9f1a14dd5e312a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1225.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=9, Acc=99.54, Loss=0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801a03092dfb4e8f805e83791dac68f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1225.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=10, Acc=99.61, Loss=0.00\n",
      "BEST MODEL at Epoch = 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29fb2b8873364c799bb11727fd3921e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1225.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=11, Acc=99.60, Loss=0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86301c3702c491eaa83d9e008b97f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1225.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=12, Acc=99.74, Loss=0.03\n",
      "BEST MODEL at Epoch = 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1411df1e45424a8b5af9caa46a708b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1225.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=13, Acc=99.69, Loss=0.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab1c3faf90d4a969a22fcbb3367a025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1225.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=14, Acc=99.66, Loss=0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c4229e5981478994ad9d0438ee632c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1225.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=15, Acc=99.72, Loss=0.05\n",
      "BEST MODEL at Epoch = 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8aa8e4a911a42a0a544632be460c897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1225.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=16, Acc=99.58, Loss=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093bb56d0b9e4763bf1490ace4cc2257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1225.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=17, Acc=99.74, Loss=0.01\n",
      "BEST MODEL at Epoch = 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955bccb8836340d98115b9240d743b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1225.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=18, Acc=99.77, Loss=0.00\n",
      "BEST MODEL at Epoch = 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b373dd6baf604668bd33c67d48e019ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1225.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch=19, Acc=99.87, Loss=0.00\n",
      "BEST MODEL at Epoch = 19\n",
      "\n",
      "{'train_loss': [163.11059016361833, 112.17023746995255, 67.29989651683718, 41.6530455268221, 33.095375760109164, 29.133335248188814, 22.520687466618256, 22.507519800423324, 14.685416374288252, 15.943816489012534, 13.93064460644473, 14.114390472642754, 10.378330527740502, 11.608633353419918, 12.348099744272758, 9.670739976643745, 14.13293377559603, 9.330683657447025, 8.788927955342388, 5.551301488467743], 'train_acc': [0.9552168367346939, 0.9648724489795918, 0.978265306122449, 0.9878188775510204, 0.9902168367346939, 0.9910586734693878, 0.9934566326530613, 0.99375, 0.9958163265306123, 0.9954464285714286, 0.9961479591836735, 0.9959821428571428, 0.9974489795918368, 0.9968622448979592, 0.996594387755102, 0.9971556122448979, 0.9958418367346938, 0.997359693877551, 0.9976530612244898, 0.9987372448979592]}\n"
     ]
    }
   ],
   "source": [
    "model.freeze_resnet()\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.train()\n",
    "model.load_state_dict(torch.load('origin_sd.pt'))\n",
    "\n",
    "start_lr = 1e-3\n",
    "lr_find_epochs = 20\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), start_lr)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "# Make lists to capture the logs\n",
    "best_metrics = {'train_loss': 1e10, \n",
    "                'train_acc': 0}\n",
    "\n",
    "metrics = {'train_loss': [], \n",
    "           'train_acc': []}\n",
    "\n",
    "    \n",
    "for e in tqdm.notebook.trange(lr_find_epochs):\n",
    "\n",
    "    predicts = []\n",
    "    y_true = []\n",
    "    total_loss = 0\n",
    "\n",
    "    for x1, x1_f, x2, x2_f, label in tqdm.notebook.tqdm(dataloader):\n",
    "\n",
    "        x1 = [ts.to(DEVICE) for ts in x1]\n",
    "        x1_f = x1_f.to(DEVICE)\n",
    "        x2 = [ts.to(DEVICE) for ts in x2]\n",
    "        x2_f = x2_f.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predict = model(x1, x1_f, x2, x2_f)[0]\n",
    "        loss = criterion(predict, label.float())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        predict = predict.detach().cpu()\n",
    "        predict = torch.sigmoid(predict)\n",
    "        predicts.extend(predict.tolist())\n",
    "        y_true.extend(label.detach().cpu().tolist())\n",
    "\n",
    "    train_acc = accuracy_score(np.array(y_true), np.array(predicts)>0.5)\n",
    "    print(f'epoch={e}, Acc={train_acc*100:.2f}, Loss={loss:.2f}')\n",
    "\n",
    "    metrics['train_acc'].append(train_acc)\n",
    "    metrics['train_loss'].append(total_loss)\n",
    "    \n",
    "    if total_loss < best_metrics['train_loss']:\n",
    "        best_metrics['train_acc'] = train_acc\n",
    "        best_metrics['train_loss'] = total_loss\n",
    "        \n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "        print(f'BEST MODEL at Epoch = {e}')\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7453333333333333"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.array(y_true).squeeze(), (np.array(predicts)>0.5).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8264700613043315"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "#model.load_state_dict(torch.load('best_model.pt'))\n",
    "predict_matrix = []\n",
    "val_loss = 0\n",
    "val_data_loader = DataLoader(BonzDataset(train_data), batch_size=32)\n",
    "for img_tensors, features, one_hot_label, label in val_data_loader:\n",
    "    img_tensors = [ts.to(DEVICE) for ts in img_tensors]\n",
    "    features = features.to(DEVICE)\n",
    "    one_hot_label = one_hot_label.to(DEVICE)\n",
    "    label = label.to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predict = model(img_tensors, features)\n",
    "    predict = predict.detach().cpu()\n",
    "    predict_matrix.extend(torch.softmax(predict, 1))\n",
    "    \n",
    "onehot_true = np.array(list(i.numpy() for i in train_data.one_hot_labels.values))\n",
    "onehot_predict = torch.stack(predict_matrix).numpy()\n",
    "\n",
    "average_precision_score(onehot_true, onehot_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 11,  7,  3,  5,  5,  6,  7,  6,  9, 14, 11, 12, 13, 14,  1, 16,\n",
       "       17, 18, 19, 10,  1,  1,  3,  3,  9,  8, 14,  5, 10, 10,  1, 18, 13,\n",
       "       13, 10, 16, 17, 18, 19,  2,  1,  0,  2,  4,  5,  6,  7,  8, 14, 15,\n",
       "       10, 15, 13, 14,  1, 19, 19, 18, 19,  0, 11, 10, 10, 11,  9,  6, 11,\n",
       "        5,  5,  1, 11, 12, 14, 12, 15, 12, 19, 18, 19,  0, 10,  0,  7, 16,\n",
       "        7,  6,  7,  8,  9, 10, 10,  6, 13, 14,  1, 16, 17, 18, 19,  0, 15,\n",
       "        0,  3, 10,  5, 16,  7,  6,  9, 10, 15, 12, 13, 11,  3, 16, 17, 18,\n",
       "       19,  0,  1,  4, 11,  4,  5,  6,  7,  5,  5,  1,  1, 12, 13, 14, 15,\n",
       "       17, 19, 18, 19,  2,  1,  1,  3,  5,  7,  6,  7,  8,  9, 10,  5, 12,\n",
       "       13, 14, 15, 16, 17, 18, 19,  0,  1,  2,  3, 11,  5,  8,  7,  8,  9,\n",
       "       10,  1, 12, 13, 14, 15, 16, 17, 18, 19,  0,  1,  2,  3,  4,  0,  6,\n",
       "        7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 11,  1,  1, 15,\n",
       "        4,  5,  6,  7,  8,  9, 10,  1, 12, 13, 14, 15, 16, 17, 18, 19,  0,\n",
       "        1,  2,  3, 11,  5,  6,  7,  8,  9, 10,  1, 12, 13, 14, 10, 16, 17,\n",
       "       18, 19,  0,  1,  2,  3,  2, 11, 12,  7,  8,  9, 10, 11, 12, 13, 14,\n",
       "       15, 16, 17, 18, 19,  0, 11,  2, 15,  4,  5,  6,  7,  8,  2, 10, 11,\n",
       "       12, 13, 14, 15, 16, 19, 18, 19], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(onehot_predict, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 10, 17, 17,  3, 14,  7,  3,  7,  3, 11, 14,  3, 14, 14, 14,  3,\n",
       "       13, 14,  3,  3, 14,  3, 14,  3, 14, 14,  3, 14, 14,  3,  3, 14, 14,\n",
       "        3,  3, 14, 14,  3,  3,  3,  6, 13, 13, 14, 14,  3,  3,  3, 14,  3,\n",
       "       14, 13, 14,  3, 14,  3, 14,  3,  3,  3,  3,  3, 14, 14, 14,  3,  7,\n",
       "        3,  3, 14, 14, 13,  3, 14, 14, 14, 14, 14,  3, 14, 14,  3, 14,  3,\n",
       "       14,  3, 14, 14,  3, 13, 14, 14,  3,  3, 14, 14, 14, 14,  3,  3,  3,\n",
       "        3, 14, 14, 14, 14, 14, 14, 13,  3,  3, 14,  3,  6, 14,  3, 16, 14,\n",
       "        3, 11, 13, 14,  7, 14,  3, 14,  3,  3, 14, 14, 14,  3,  7, 14,  3,\n",
       "        3,  3, 14, 14], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "predict_matrix = []\n",
    "val_data_loader = DataLoader(BonzDataset(test_data), batch_size=32)\n",
    "for img_tensors, features in val_data_loader:\n",
    "    img_tensors = [ts.to(DEVICE) for ts in img_tensors]\n",
    "    features = features.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        predict = model(img_tensors, features)\n",
    "    predict = predict.detach().cpu()\n",
    "    predict_matrix.extend(torch.softmax(predict, 1))\n",
    "\n",
    "onehot_predict = torch.stack(predict_matrix).numpy()\n",
    "\n",
    "COLUMN_NAMES = ['act'+str(i)+str(j) for i in range(2) for j in range(10)]\n",
    "COLUMN_NAMES.pop(0)\n",
    "COLUMN_NAMES.append('act20')\n",
    "\n",
    "df_prob = pd.DataFrame(data=onehot_predict, columns=COLUMN_NAMES)\n",
    "df_prob['event'] = test_data['image_prefixes']\n",
    "\n",
    "submission = []\n",
    "for act in list(df_prob.keys())[:-1]:\n",
    "    ranked_ = df_prob.sort_values(by=[act], ascending=False)['event'].values\n",
    "    ranked_ = act+' '+ranked_\n",
    "    submission.extend(ranked_)\n",
    "\n",
    "pd.DataFrame(submission).to_csv('submission.txt', header=False, index=False)\n",
    "\n",
    "np.argmax(onehot_predict, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
